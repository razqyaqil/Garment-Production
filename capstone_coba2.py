# -*- coding: utf-8 -*-
"""Capstone coba2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1USMbVzeUBYajsf9sedrdMlASkNqyl_yh

### Upload Data
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
from scipy.stats import norm
from scipy import stats
import warnings
import cv2
warnings.filterwarnings('ignore')
# %matplotlib inline

from google.colab import drive
drive.mount('/content/drive')

path = '/content/drive/MyDrive/Colab Notebooks/garments_worker_productivity.csv'
df = pd.read_csv(path)
df

#df = pd.read_csv("/content/garments_worker_productivity.csv")

"""## EDA"""

df.info()

"""### Change Value in Department
Change value of 'finishing ' to 'finishing' in department column
"""

df['department'] = df['department'].replace(['finishing '],'finishing')
df['department'] = df['department'].replace(['sweing'],'sewing')
df['department'].unique()

"""### Upround the value in No_of_Workers
There are some decimal data in column that shows number of workers, so we could round up the decimal values
"""

df['no_of_workers'] = df['no_of_workers'].apply(np.ceil)
df['no_of_workers'].unique()

"""### Missing Values"""

#Missing value
total = df.isnull().sum().sort_values(ascending=False)
percent = (df.isnull().sum()/df.isnull().count()).sort_values(ascending=False)
missing_data = pd.concat([total, percent], axis=1, keys=['total', 'percent'])
missing_data.head(14)

fill_value = df['wip'].median()
df['wip'] = df['wip'].fillna(fill_value)
df.head()

"""### Find Duplicate"""

df[df.duplicated()]
df.drop_duplicates()

df.describe()

"""### Histogram Target Variable"""

image1 = df.hist(bins=30, figsize=(10, 10))
image1
#cv2.imwrite('/content/drive/MyDrive/Colab Notebooks/Images',image1)

"""The distribution graphs above show that:

1. actual_productivity has multiple lower outliers, potentially leading to a negative skew as we can observe the longer tail to the left.
2. Most of our attributes are heavily skewed, both positive and negative, except for perhaps actual_productivity and team, which appears to be approximately normal and uniform respectively.
3. There is 0 idle time and idle workers for the majority of the time.
There is 0 incentive offered for the majority of the time.
4. Very few to none style changes, except for a few products.
5. 12 teams working with quite uniform distribution of activities. Team 1 and 2 have the highest number of activities.
6. Number of workers in a team can vary greatly, with most having around 8 or 58 workers.
7. Targeted productivity is set at 0.8 for the majority of the time.
8. The allocated time for a task is usually within 20 minutes, most being around 3 minutes.

### Bar Chart for Categorical Data
"""

#Day
sns.catplot(x="day", kind="count", data=df)

#Dept
sns.catplot(x="department", kind="count", data=df)

#Quarter
sns.catplot(x="quarter", kind="count", data=df)

#Team
sns.catplot(x="team", kind="count", data=df)

"""1. Production activities are spread quite evenly throughout weekdays and weekends, except for Friday, which seems to be a day off.
2. There are close to 200 more sewing tasks than finishing in total.
3. More than half production activities happen during the first two quarters of the month.

### Skewness dan Kurtosis target variable
Skewness to measure how symmetrical the distribution is (normal = 0).
Kurtosis to measure how steep the distribution is (normal = 3)

#### actual_productivity
"""

print("Skewness: %f" % df['actual_productivity'].skew())
print("Kurtosis: %f" % df['actual_productivity'].kurt())

"""Therefore, the distribution of actual_productivity is not normal because the skewness is less than zero (negative skewness) and the kurtosis is less than 3 (platykurtic)

### Boxplot for target variable
"""

data = pd.concat([df['actual_productivity'], df['team']], axis=1)
f, ax = plt.subplots(figsize=(10, 10))
fig = sns.boxplot(x='team', y="actual_productivity", data=data)

"""Team 1, 2, 3, 4, 12 are the most productive because these teams have actual_productivity above the median of all teams."""

data = pd.concat([df['actual_productivity'], df['department']], axis=1)
f, ax = plt.subplots(figsize=(8, 6))
fig = sns.boxplot(x='department', y="actual_productivity", data=data)

"""Outliers are mostly in sweing department when it comes to actual productivity."""

data = pd.concat([df['actual_productivity'], df['quarter']], axis=1)
f, ax = plt.subplots(figsize=(8, 6))
fig = sns.boxplot(x='quarter', y="actual_productivity", data=data)

"""The outliers are mostly in Quarter 1 when it comes to actual productivity

### Correlation Map for each Variable
"""

plt.figure(figsize=(10,8))
ax = sns.heatmap(df.corr(), cmap = "coolwarm", annot=True, linewidth=2)

"""### Correlation Map yang korelasi terhadap target variable >= 0,5"""

hig_corr = df.corr()
hig_corr_features = hig_corr.index[abs(hig_corr["actual_productivity"]) >= 0.5]

plt.figure(figsize=(6,6))
ax = sns.heatmap(df[hig_corr_features].corr(), cmap = "coolwarm", annot=True, linewidth=3)

"""There is no dependent variable that has strong correlation with the target variable.

Most correlations between attributes are weak and insignificant. There are only a few moderate and strong positive correlations :
- smv and no_of_workers have a strong positive correlation (0.91). This makes sense because we would expect the longer the task, the more workers are allocated to it.
- overtime and no_of_workers have a moderate positive correlation (0.73), as well as overtime and smv (0.67).
- idle_time and idle_men also have a moderate positive correlation (0.56), most likely because they are mostly 0s.

### Investigate the connections of the 3 categorical variables (day, quarter, department) to others variables, especially target variable (actual_productivity)

#### Day
"""

#Day and Team
data = pd.concat([df['team'], df['day']], axis=1)
f, ax = plt.subplots(figsize=(6, 3))
fig = sns.boxplot(x='day', y="team", data=data)

"""No differences between the days of the week for team variable."""

#Day and no_of_workers
data = pd.concat([df['no_of_workers'], df['day']], axis=1)
f, ax = plt.subplots(figsize=(6, 3))
fig = sns.boxplot(x='day', y="no_of_workers", data=data)

"""No differences between the days of the week for number of workers. However, Wednesday has number of workers more than any other days."""

#Day and no_of_style_change
data = pd.concat([df['no_of_style_change'], df['day']], axis=1)
f, ax = plt.subplots(figsize=(6, 3))
fig = sns.boxplot(x='day', y="no_of_style_change", data=data)

#Day and targeted_productivity
data = pd.concat([df['targeted_productivity'], df['day']], axis=1)
f, ax = plt.subplots(figsize=(6, 3))
fig = sns.boxplot(x='day', y="targeted_productivity", data=data)

#Day and smv
data = pd.concat([df['smv'], df['day']], axis=1)
f, ax = plt.subplots(figsize=(6, 3))
fig = sns.boxplot(x='day', y="smv", data=data)

#Day and wip
data = pd.concat([df['wip'], df['day']], axis=1)
f, ax = plt.subplots(figsize=(6, 3))
fig = sns.boxplot(x='day', y="wip", data=data)

"""Monday has more outliers of WIP than any others days, which makes sense as it is the beginning of working period."""

#day and incentive
data = pd.concat([df['incentive'], df['day']], axis=1)
f, ax = plt.subplots(figsize=(6, 3))
fig = sns.boxplot(x='day', y="incentive", data=data)

"""Monday has more outliers of incentive than any others days."""

#Day and actual_productivity
data = pd.concat([df['actual_productivity'], df['day']], axis=1)
f, ax = plt.subplots(figsize=(6, 3))
fig = sns.boxplot(x='day', y="actual_productivity", data=data)

"""Monday and Tuesday seem to have higher actual productivity than any other days. But there are still lots of outliers in those days.

No differences between the days of the week for team variable.
No differences between the days of the week for number of workers. However, Wednesday has number of workers more than any other days.
Monday has more outliers of WIP than any others days, which makes sense as it is the beginning of working period.
Monday has more outliers of incentive than any others days.
Monday and Tuesday seem to have higher actual productivity than any other days. But there are still lots of outliers in those days.

#### Quarter
"""

#Quarter and team
data = pd.concat([df['team'], df['quarter']], axis=1)
f, ax = plt.subplots(figsize=(6, 3))
fig = sns.boxplot(x='quarter', y="team", data=data)

#Quarter and no_of_workers
data = pd.concat([df['no_of_workers'], df['quarter']], axis=1)
f, ax = plt.subplots(figsize=(6, 3))
fig = sns.boxplot(x='quarter', y="no_of_workers", data=data)

"""Quarter 3 seems to have more workers than any other quarters."""

#Quarter and no_of_style_change
data = pd.concat([df['no_of_style_change'], df['quarter']], axis=1)
f, ax = plt.subplots(figsize=(6, 3))
fig = sns.boxplot(x='quarter', y="no_of_style_change", data=data)

#Quarter and targeted_productivity
data = pd.concat([df['targeted_productivity'], df['quarter']], axis=1)
f, ax = plt.subplots(figsize=(6, 3))
fig = sns.boxplot(x='quarter', y="targeted_productivity", data=data)

#Quarter and smv
data = pd.concat([df['smv'], df['quarter']], axis=1)
f, ax = plt.subplots(figsize=(6, 3))
fig = sns.boxplot(x='quarter', y="smv", data=data)

"""Quarter 5 seems to have the least smv than any other quarters."""

#Quarter and wip
data = pd.concat([df['wip'], df['quarter']], axis=1)
f, ax = plt.subplots(figsize=(6, 3))
fig = sns.boxplot(x='quarter', y="wip", data=data)

"""Quarter 1 has the most outliers for wip, which makes sense as it is the beginning of working period."""

#Quarter and over_time
data = pd.concat([df['over_time'], df['quarter']], axis=1)
f, ax = plt.subplots(figsize=(6, 3))
fig = sns.boxplot(x='quarter', y="over_time", data=data)

#Quarter and incentive
data = pd.concat([df['incentive'], df['quarter']], axis=1)
f, ax = plt.subplots(figsize=(6, 3))
fig = sns.boxplot(x='quarter', y="incentive", data=data)

"""Quarter 2 has the most outliers for incentive than any other quarters."""

#Quarter and idle_time
data = pd.concat([df['idle_time'], df['quarter']], axis=1)
f, ax = plt.subplots(figsize=(6, 3))
fig = sns.boxplot(x='quarter', y="idle_time", data=data)

"""Quarter 1 has the most outliers for idle time than any other quarters."""

#Quarter and idle_men
data = pd.concat([df['idle_men'], df['quarter']], axis=1)
f, ax = plt.subplots(figsize=(6, 3))
fig = sns.boxplot(x='quarter', y="idle_men", data=data)

"""Quarter 1,3, and 4 have the most outliers for idle men than any other quarters. Quarter 1 is understandable since it is the beginning of working period."""

#Quarter and actual_productivity
data = pd.concat([df['actual_productivity'], df['quarter']], axis=1)
f, ax = plt.subplots(figsize=(6, 3))
fig = sns.boxplot(x='quarter', y="actual_productivity", data=data)

"""Quarter 5 seems to have higher actual productivity than any other quarters. However, Quarter 3 and 4 have lower productivity than the other quarters (lower than targeted productivity = 0.8).

1. Quarter 5 appears to have higher actual_productivity than all the other quarters.
2. Quarter 1 has the most outliers for wip and idle_time, which makes sense as it is the beginning of working period.
3. Quarter 2 has the most outliers for incentive.
4. Quarter 3 and 4 seems to be the low point for actual_productivity. Also they have the most outliers in idle_men.

#### Department
"""

#Department and team
data = pd.concat([df['team'], df['department']], axis=1)
f, ax = plt.subplots(figsize=(6, 3))
fig = sns.boxplot(x='department', y="team", data=data)

#Department and no_of_workers
data = pd.concat([df['no_of_workers'], df['department']], axis=1)
f, ax = plt.subplots(figsize=(6, 3))
fig = sns.boxplot(x='department', y="no_of_workers", data=data)

#Department and no_of_style_change
data = pd.concat([df['no_of_style_change'], df['department']], axis=1)
f, ax = plt.subplots(figsize=(6, 3))
fig = sns.boxplot(x='department', y="no_of_style_change", data=data)

#Department and targeted_productivity
data = pd.concat([df['targeted_productivity'], df['department']], axis=1)
f, ax = plt.subplots(figsize=(6, 3))
fig = sns.boxplot(x='department', y="targeted_productivity", data=data)

#Department and smv
data = pd.concat([df['smv'], df['department']], axis=1)
f, ax = plt.subplots(figsize=(6, 3))
fig = sns.boxplot(x='department', y="smv", data=data)

#Department and wip
data = pd.concat([df['wip'], df['department']], axis=1)
f, ax = plt.subplots(figsize=(6, 3))
fig = sns.boxplot(x='department', y="wip", data=data)

#Department and over_time
data = pd.concat([df['over_time'], df['department']], axis=1)
f, ax = plt.subplots(figsize=(6, 3))
fig = sns.boxplot(x='department', y="over_time", data=data)

#Department and incentive
data = pd.concat([df['incentive'], df['department']], axis=1)
f, ax = plt.subplots(figsize=(6, 3))
fig = sns.boxplot(x='department', y="incentive", data=data)

#Department and idle_time
data = pd.concat([df['idle_time'], df['department']], axis=1)
f, ax = plt.subplots(figsize=(6, 3))
fig = sns.boxplot(x='department', y="idle_time", data=data)

#Department and idle_men
data = pd.concat([df['idle_men'], df['department']], axis=1)
f, ax = plt.subplots(figsize=(6, 3))
fig = sns.boxplot(x='department', y="idle_men", data=data)

#Department and actual_productivity
data = pd.concat([df['actual_productivity'], df['department']], axis=1)
f, ax = plt.subplots(figsize=(6, 3))
fig = sns.boxplot(x='department', y="actual_productivity", data=data)

"""1. The smv is generally longer for the sewing department, compared to the finishing department.
2. The sewing department has more outliers when it comes to wip, idle_time, and idle_men.
3. The sewing department works over_time for much longer on average.
4. The sewing department has more no_of_workers than the finishing department, with an average of around 60 workers, compared to 12 for finishing.
5. On average, the 2 departments seem to be equal in terms of actual_productivity, but the sewing department has more consistent average actual_productivity with many more unproductive outliers.

### Investigate if date attribute has an effect on actual_productivity
"""

data = pd.concat([df['date'], df['actual_productivity']], axis=1)
f, ax = plt.subplots(figsize=(100, 20))
fig = sns.boxplot(x='date', y="actual_productivity", data=data)

"""#PREPROCESSING

##Detect Outliers

### Incentive
"""

sns.boxplot(data=df,y='incentive')

#Removing outlier in incentive
Q1 = df["incentive"].quantile(0.25)
Q3 = df["incentive"].quantile(0.75)
IQR = Q3-Q1
upbound = Q3 + 1.5*IQR
lowbound = Q1 - 1.5*IQR

outliers = df[df["incentive"]>upbound]
outliers

#remove outlier and zero

df_incentive = df.loc[~((df['incentive'] == 0) | (df['incentive'] >= upbound))]
df_incentive

sns.boxplot(data=df_incentive,y='incentive')

x = df_incentive["incentive"]
y = df_incentive["actual_productivity"]
plt.scatter(x, y)
plt.rcParams.update({'figure.figsize':(6,3), 'figure.dpi':100})
plt.title('Simple Scatter plot')
plt.xlabel('incentive')
plt.ylabel('actual_productivity')
sns.lmplot(x="incentive", y="actual_productivity", data=df_incentive);
plt.show()

stats.pearsonr(df_incentive['incentive'], df_incentive['actual_productivity'])

"""It's visible that there is strong correlation between incentive and actual productivity if outliers and zeros are removed. Pearson score is 0.805

#### Investigate incentive and the teams who receive it
Assumption : without removing outliers and zeros in incentive column
"""

plt.bar(df['team'],df['incentive'])
plt.title('Incentive vs Team')
plt.xlabel('team')
plt.ylabel('incentive')
plt.show()

"""Team 9 and team 5 received the highest incentive respectively. Does it mean team 9 and team 5 also become the most productive team ?

#### Investigate team and actual productivity
"""

plt.bar(df['team'],df['actual_productivity'])
plt.title('actual productivity vs team')
plt.xlabel('team')
plt.ylabel('actual_productivity')
plt.show()

"""Turned out team 9 and team 5 are not the most productive team. The most productive team is team 1 and team 2.

The least productive teams are team 6 and team 7, and they also received the least incentive

### wip
"""

sns.boxplot(data=df,y='wip')

#Removing outlier in smv
Q1 = df["wip"].quantile(0.25)
Q3 = df["wip"].quantile(0.75)
IQR = Q3-Q1
upbound = Q3 + 1.5*IQR
lowbound = Q1 - 1.5*IQR

outliers = df[df["wip"]>upbound]
outliers

#remove outlier
df_wip = df.loc[~(df['wip'] >= upbound)]
df_wip

sns.lmplot(x="smv", y="actual_productivity", data=df_wip);
plt.show()

stats.pearsonr(df_wip['wip'], df_wip['actual_productivity'])

"""Insiginificant correlation between actual productivity and smv"""



"""### over_time"""

sns.boxplot(data=df,y='over_time')

#Removing outlier in smv
Q1 = df["over_time"].quantile(0.25)
Q3 = df["over_time"].quantile(0.75)
IQR = Q3-Q1
upbound = Q3 + 1.5*IQR
lowbound = Q1 - 1.5*IQR

outliers = df[df["over_time"]>upbound]
outliers

#remove outlier
df_over_time = df.loc[~(df['over_time'] >= upbound)]
df_over_time

sns.lmplot(x="over_time", y="actual_productivity", data=df_over_time);
plt.show()

stats.pearsonr(df_over_time['over_time'], df_over_time['actual_productivity'])

"""Insiginificant correlation between actual productivity and over time even after removing the outliers."""



"""### smv"""

sns.boxplot(data=df,y='smv')

#Removing outlier in idle_time
Q1 = df["smv"].quantile(0.25)
Q3 = df["smv"].quantile(0.75)
IQR = Q3-Q1
upbound = Q3 + 1.5*IQR
lowbound = Q1 - 1.5*IQR

outliers = df[df["smv"]>upbound]
outliers

#remove outlier
df_smv = df.loc[~(df['smv'] >= upbound)]
df_smv

sns.lmplot(x="smv", y="actual_productivity", data=df_smv);
plt.show()

stats.pearsonr(df_smv['smv'], df_smv['actual_productivity'])

"""###actual productivity"""

Q1 = df["actual_productivity"].quantile(0.25)
Q3 = df["actual_productivity"].quantile(0.75)
IQR = Q3-Q1
upbound = Q3 + 1.5*IQR
lowbound = Q1 - 1.5*IQR

outliers = df[df["actual_productivity"]<lowbound]
outliers

df.loc[(df["actual_productivity"]<lowbound),"actual_productivity"] = lowbound
sns.boxplot(data=df,y='actual_productivity')

"""###target productivity"""

sns.boxplot(data=df,y='targeted_productivity')

Q1 = df["targeted_productivity"].quantile(0.25)
Q3 = df["targeted_productivity"].quantile(0.75)
IQR = Q3-Q1
upbound = Q3 + 1.5*IQR
lowbound = Q1 - 1.5*IQR

outliers = df[df["targeted_productivity"]<lowbound]
outliers

df.loc[(df["targeted_productivity"]<lowbound),"targeted_productivity"] = lowbound
sns.boxplot(data=df,y='targeted_productivity')



"""##Creating Target Label Productivity"""

tmp_df = df

tmp_df['performance']=tmp_df.actual_productivity-tmp_df.targeted_productivity
tmp_df.columns

tmp_df.loc[tmp_df['performance']<0,'Productivity'] = 0
tmp_df.loc[(tmp_df['performance']>=0), 'Productivity'] = 1
tmp_df.head()

"""If performance is less than 0, it means the performance is non-productive (0). 

If actual_productivity is more or equal to 0, it means the performance is productive (1). 
"""

ax = sns.countplot(x = 'Productivity', data = tmp_df, palette='Set1')
plt.xlabel('Productivity')

plt.show()

#df['Target_label'] = [-1 if x==-1 else 1 for x in df['Target_label']]

#ax = sns.countplot(x = 'Target_label', data = df, palette='Set1')
#plt.xlabel('No of Target_label')

#plt.show()

"""##Label Encoding"""

from sklearn.preprocessing import LabelEncoder
le = LabelEncoder()
tmp_df["department"] = le.fit_transform(tmp_df["department"])
tmp_df.head()

"""## Membuat Dummy"""

def create_dummies(tmp_df,column_name):
    dummies = pd.get_dummies(tmp_df[column_name])
    tmp_df = pd.concat([tmp_df,dummies],axis=1)
    return tmp_df

tmp_df = create_dummies(tmp_df,"quarter")
tmp_df = create_dummies(tmp_df,"day")

tmp_df.drop(['quarter'],axis=1,inplace=True)
tmp_df.drop(['day'],axis=1,inplace=True)
tmp_df.columns

tmp_df

"""##Train Test Split"""

#Experiment 2 : Not using targeted_productivity as X
from sklearn.model_selection import train_test_split

columns = ['department', 'team', 'smv', 'wip', 'over_time', 'incentive', 'idle_time', 'idle_men',
       'no_of_style_change', 'no_of_workers', 'Quarter1', 'Quarter2',
       'Quarter3', 'Quarter4', 'Quarter5', 'Monday', 'Saturday', 'Sunday', 'Thursday', 'Tuesday', 'Wednesday']

X = tmp_df[columns]
Y = tmp_df['Productivity']

X_train, X_test, Y_train, Y_test = train_test_split(
    X, Y, test_size=0.2,random_state=0)

X_train.shape

Y_train.shape

X_test.shape

Y_test.shape

"""## Scaling
Using normalization because the distribution of all variables are not normal
"""

# Feature Scaling
from sklearn.preprocessing import StandardScaler, MinMaxScaler
sc = StandardScaler()
mm = MinMaxScaler()

X_train_scaled = mm.fit_transform(X_train)
X_test_scaled = mm.transform(X_test)

X_train_scaled = pd.DataFrame(X_train_scaled, columns=X.columns)
X_test_scaled = pd.DataFrame(X_test_scaled, columns=X_train_scaled.columns)

X_train_scaled

"""# CLASSIFICATION MODELLING"""

from sklearn.neighbors import KNeighborsClassifier #KNN
from sklearn.tree import DecisionTreeClassifier #Decision Tree
from sklearn.ensemble import RandomForestClassifier #Random Forest
from sklearn.inspection import permutation_importance
from sklearn.metrics import confusion_matrix 
from sklearn.metrics import classification_report

# evaluation metrics
def classification_eval (aktual, prediksi, name):
    cm = confusion_matrix(aktual, prediksi)
    tp = cm[1][1]
    tn = cm[0][0]
    fp = cm[0][1]
    fn = cm[1][0]
    
    accuracy = round((tp+tn) / (tp+tn+fp+fn) * 100, 2)
    precision = round((tp) / (tp+fp) * 100, 2)
    recall = round((tp) / (tp+fn) * 100, 2)
    
    print('Evaluation Model:', name)
    print(cm)
    print('Accuracy   :', accuracy, '%')
    print('Precision  :', precision, '%')
    print('Recall     :', recall, '%')

"""## Eksperimen (Not Using Target Productivity as X)

### KNN
"""

#Find optimal value of K
error_rate = []
# Will take some time
for i in range(1,40):
 
 knn = KNeighborsClassifier(n_neighbors=i)
 knn.fit(X_train,Y_train)
 pred_i = knn.predict(X_test)
 error_rate.append(np.mean(pred_i != Y_test))

import matplotlib.pyplot as plt

plt.figure(figsize=(10,6))
plt.plot(range(1,40),error_rate,color='blue', linestyle='dashed', marker='o',
 markerfacecolor='red', markersize=10)
plt.title('Error Rate vs. K Value')
plt.xlabel('K')
plt.ylabel('Error Rate')

knn = KNeighborsClassifier(n_neighbors=3)
knn.fit(X2_train_scaled,Y2_train)

Y2_train_pred = knn.predict(X2_train_scaled)
Y2_test_pred = knn.predict(X2_test_scaled)

classification_eval(Y2_train, Y2_train_pred, 'KNN Training')

k3 = classification_eval(Y2_test, Y2_test_pred, 'KNN Testing')
k3

"""### Decision Tree"""

### Find optimal parameter

from sklearn.metrics import roc_curve, auc

max_depths = np.linspace(1, 32, 32, endpoint=True)
train_results = []
test_results = []
for max_depth in max_depths:
   dt = DecisionTreeClassifier(max_depth=max_depth)
   dt.fit(X2_train,Y2_train)
   train_pred = dt.predict(X2_train)
   false_positive_rate, true_positive_rate, thresholds = roc_curve(Y2_train, train_pred)
   roc_auc = auc(false_positive_rate, true_positive_rate)
   # Add auc score to previous train results
   train_results.append(roc_auc)
   y_pred = dt.predict(X2_test)
   false_positive_rate, true_positive_rate, thresholds = roc_curve(Y2_test, y_pred)
   roc_auc = auc(false_positive_rate, true_positive_rate)
   # Add auc score to previous test results
   test_results.append(roc_auc)
from matplotlib.legend_handler import HandlerLine2D
line1, = plt.plot(max_depths, train_results, 'b', label='Train AUC')
line2, = plt.plot(max_depths, test_results, 'r', label='Test AUC')
plt.legend(handler_map={line1: HandlerLine2D(numpoints=2)})
plt.ylabel('AUC score')
plt.xlabel('Tree depth')
plt.show()

## Decision Tree Model

dectree = DecisionTreeClassifier(max_depth=8, random_state = 50)
dectree.fit(X2_train_scaled,Y2_train)

y_train_pred = dectree.predict(X2_train_scaled)
y_test_pred = dectree.predict(X2_test_scaled)

pd.DataFrame(y_test_pred, columns=['Productivity'])

classification_eval(Y2_train, y_train_pred, 'Decision Tree Training')

classification_eval(Y2_test, y_test_pred, 'Decision Tree Testing')

"""### Random Forest"""

ranfor = RandomForestClassifier(max_depth=8, random_state = 50)
ranfor.fit(X_train_scaled,Y_train)

y_train_pred = ranfor.predict(X_train_scaled)
y_test_pred = ranfor.predict(X_test_scaled)

classification_eval(Y_train, y_train_pred, 'Random Forest Training')

classification_eval(Y_test, y_test_pred, 'Random Forest testing')

sort = ranfor.feature_importances_.argsort()
plt.barh(X_train_scaled.columns[sort], ranfor.feature_importances_[sort])
plt.xlabel("Feature Importance")

print(classification_report(Y_test, y_test_pred))

"""### Hyperparameter Tuning"""

#Grid Search
from sklearn.model_selection import GridSearchCV

max_features_range = np.arange(1,10,1)
n_estimators_range = np.arange(10,201,100)
param_grid = dict(max_features=max_features_range, n_estimators=n_estimators_range, random_state=[50])

rf = RandomForestClassifier()
grid = GridSearchCV(estimator=rf, param_grid=param_grid, cv=5, scoring='f1_macro')

grid.fit(X_train_scaled,Y_train)

# Commented out IPython magic to ensure Python compatibility.
print('The best parameters are %s with a score of %0.2f'
#       % (grid.best_params_, grid.best_score_))



"""### Random Forest"""

ranfor = RandomForestClassifier(max_features = 8, n_estimators = 110, random_state = 50)
ranfor.fit(X_train_scaled,Y_train)

y_train_pred = ranfor.predict(X_train_scaled)
y_test_pred = ranfor.predict(X_test_scaled)

classification_eval(Y_train, y_train_pred, 'Random Forest Training')

classification_eval(Y_test, y_test_pred, 'Random Forest testing')

print(classification_report(Y_test, y_test_pred))

"""## SMOTEENN
class imblearn.combine.SMOTEENN(*, sampling_strategy='auto', random_state=None, smote=None, enn=None, n_jobs=None)

Over-sampling using SMOTE and cleaning using ENN.
Combine over- and under-sampling using SMOTE and Edited Nearest Neighbours.
"""

from collections import Counter
from sklearn.datasets import make_classification
from imblearn.combine import SMOTEENN 
sme = SMOTEENN(random_state=42)
X_res, Y_res = sme.fit_resample(X_train, Y_train)

"""**Modelling dengan SMOTEENN**"""

# Feature Scaling
from sklearn.preprocessing import StandardScaler, MinMaxScaler
sc = StandardScaler()
mm = MinMaxScaler()

X_res_scaled = mm.fit_transform(X_res)
X_test_scaled_smot = mm.transform(X_test)

X_res_scaled = pd.DataFrame(X_res_scaled, columns=X.columns)
X_test_scaled_smot = pd.DataFrame(X_test_scaled_smot, columns=X_res_scaled.columns)

ranfor = RandomForestClassifier(max_depth=10, random_state = 50)
ranfor.fit(X_res_scaled,Y_res)

y_train_pred_smot = ranfor.predict(X_res_scaled)
y_test_pred_smot = ranfor.predict(X_test_scaled_smot)

classification_eval(Y_res, y_train_pred_smot, 'Random Forest Training')

classification_eval(Y_test, y_test_pred_smot, 'Random Forest testing')

print(classification_report(Y_test, y_test_pred_smot))

"""## Hyperparameter Tuning"""

#Grid Search
#from sklearn.model_selection import GridSearchCV

#max_features_range = np.arange(1,10,1)
#n_estimators_range = np.arange(10,201,100)
#param_grid = dict(max_features=max_features_range, n_estimators=n_estimators_range, random_state=[50])

#rf = RandomForestClassifier()
#grid = GridSearchCV(estimator=rf, param_grid=param_grid, cv=5, scoring='f1_macro')

#grid.fit(X_res_scaled,Y_res)

#print('The best parameters are %s with a score of %0.2f'
      #% (grid.best_params_, grid.best_score_))

"""# Recommendation

Berdasarkan tabel Feature Importance, variabel SMV, Incentive, dan No of Workers menjadi 3 variabel teratas yang mempengaruhi model klasifikasi produktivitas. 

Perusahaan dapat meningkatkan ketiga variabel tersebut untuk meningkatkan produktivitas di masa depan.

Buat scatter plot untuk incentive & performance.
Buat catplot untuk SMV & performance/productivity.

Ingin melihat apakah semakin rendah SMV, semakin tinggi productivity atau sebaliknya.
"""

f, ax = plt.subplots(figsize=(30, 10))
sns.boxplot(data=tmp_df, x="incentive", y="performance")

g = sns.regplot(x='incentive', y="performance", data=tmp_df)

sns.catplot(data=tmp_df, x="Productivity", y="incentive")

"""Semakin tinggi incentive, semakin produktif """

f, ax = plt.subplots(figsize=(40, 20))
fig = sns.boxplot(x='smv', y="performance", data=tmp_df)

g = sns.regplot(x='smv', y="performance", data=tmp_df)

sns.catplot(data=tmp_df, x="Productivity", y="smv")

"""Dari boxplot, dapat disimpulkan bahwa semakin tinggi SMV, semakin rendah productivity"""

f, ax = plt.subplots(figsize=(40, 20))
fig = sns.boxplot(x='no_of_workers', y="performance", data=tmp_df)

g = sns.regplot(x='no_of_workers', y="performance", data=tmp_df)

sns.catplot(data=tmp_df, x="Productivity", y="no_of_workers")

g = sns.regplot(x='over_time', y="performance", data=tmp_df)

sns.catplot(data=tmp_df, x="Productivity", y="over_time")

g = sns.regplot(x='team', y="performance", data=tmp_df)

g = sns.regplot(x='idle_time', y="performance", data=tmp_df)

sns.catplot(data=tmp_df, x="Productivity", y="idle_time")

g = sns.regplot(x='idle_men', y="performance", data=tmp_df)

sns.catplot(data=tmp_df, x="Productivity", y="idle_men")

"""Mengurangi idle_men dan idle_time untuk meningkatkan productivity"""